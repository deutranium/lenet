{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as util\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layers():\n",
    "    class CONV():\n",
    "        def __init__(self, inputs_channel, num_filters, kernel_size):\n",
    "          self.F = num_filters\n",
    "          self.K = kernel_size\n",
    "          self.C = inputs_channel\n",
    "\n",
    "          self.weights = 2*(np.random.rand(self.F,self.C, self.K, self.K)-0.5)\n",
    "          self.bias = 2*(np.random.rand(self.F, 1)-0.5)\n",
    "\n",
    "        def forward(self, inputs, padding, stride):\n",
    "            C = inputs.shape[0]\n",
    "            W = inputs.shape[1]+2*padding\n",
    "            H = inputs.shape[2]+2*padding\n",
    "\n",
    "            self.inputs = np.zeros((C, W, H))\n",
    "\n",
    "            for c in range(inputs.shape[0]):\n",
    "                self.inputs[c,:,:] = util.padder(inputs[c,:,:], padding)\n",
    "\n",
    "            return util.conv2d(self.inputs, self.weights, self.bias, padding, self.K, self.F, stride)\n",
    "          \n",
    "        def backward(self, dy, stride, learning_rate):\n",
    "            dy = util.back_tanh(dy)\n",
    "\n",
    "            C, W, H = self.inputs.shape\n",
    "\n",
    "            dx = np.zeros(self.inputs.shape)\n",
    "            dw = np.zeros(self.weights.shape)\n",
    "            db = np.zeros(self.bias.shape)\n",
    "\n",
    "            if len(dy.shape)==2:\n",
    "              dy = np.array([dy])\n",
    "            F, W, H = dy.shape\n",
    "\n",
    "            for f in range(F):\n",
    "                for w in range(0, W-self.K, stride):\n",
    "                    for h in range(0, H-self.K, stride):\n",
    "                        dw[f,:,:,:]+=dy[f,w,h]*self.inputs[:,w:w+self.K,h:h+self.K]\n",
    "                        dx[:,w:w+self.K,h:h+self.K]+=dy[f,w,h]*self.weights[f,:,:,:]\n",
    "\n",
    "            for f in range(F):\n",
    "                db[f] = np.sum(dy[f, :, :])\n",
    "\n",
    "            self.weights -= learning_rate * dw\n",
    "            self.bias -= learning_rate * db\n",
    "\n",
    "            return dx\n",
    "    \n",
    "    class POOL():\n",
    "        def __init__(self, pool_size):\n",
    "            self.pool = pool_size\n",
    "        \n",
    "        def forward(self, data, stride):\n",
    "            self.inputs = data\n",
    "            return util.avg_pool(data,self.pool,stride)\n",
    "        # change later\n",
    "        def backward(self, dy):\n",
    "            C, W, H = self.inputs.shape\n",
    "            dx = np.zeros(self.inputs.shape)\n",
    "            \n",
    "            for c in range(C):\n",
    "                for w in range(0, W, self.pool):\n",
    "                    for h in range(0, H, self.pool):\n",
    "                        st = np.argmax(self.inputs[c,w:w+self.pool,h:h+self.pool])\n",
    "                        (idx, idy) = np.unravel_index(st, (self.pool, self.pool))\n",
    "                        dx[c, w+idx, h+idy] = dy[c, w//self.pool, h//self.pool]\n",
    "            return dx\n",
    "    \n",
    "    class DENSE():\n",
    "        def __init__(self, num_inputs, num_outputs, act):\n",
    "            self.weights = 2*(np.random.rand(num_inputs, num_outputs)-0.5)\n",
    "            self.bias = 2*(np.random.rand(num_outputs, 1)-0.5)\n",
    "            self.act=act\n",
    "        \n",
    "        def forward(self, data):\n",
    "            self.inputs = data\n",
    "            if self.act == 'tanh':\n",
    "              return util.tanh(util.vanilla(data,self.weights,self.bias))\n",
    "            elif self.act == 'softmax':\n",
    "              self.out = util.softmax(util.vanilla(data,self.weights,self.bias)[:,0])\n",
    "              return self.out\n",
    "\n",
    "        def backward(self, dy, learning_rate):\n",
    "            # print(\"blah\",dy.shape)\n",
    "            if self.act == 'tanh':\n",
    "                dy = util.back_tanh(dy).T\n",
    "                dw = dy.dot(self.inputs.T)\n",
    "                db = np.sum(dy, axis=1, keepdims=True)\n",
    "                dx = np.dot(dy.T, self.weights.T)\n",
    "            elif self.act=='softmax':\n",
    "                # print(\"bleh\",(self.out.T - dy.reshape(dy.shape[0],1)).shape)\n",
    "                # print(self.out.T)\n",
    "                # print(dy.reshape(dy.shape[0],1))\n",
    "                # print(self.out.T - dy.reshape(dy.shape[0],1))\n",
    "                # dy = self.out.T - dy.reshape(dy.shape[0],1)\n",
    "                # dy = np.square(self.out.T - dy).reshape(dy.shape[0],1)\n",
    "                out_num = dy.shape[0]\n",
    "                p = dy.reshape(1,out_num)*self.out.T\n",
    "                dy = -np.log(p).T\n",
    "                dw = dy.dot(self.inputs.T)\n",
    "                db = np.sum(dy, axis=1, keepdims=True)\n",
    "                dx = np.dot(dy.T, self.weights.T)\n",
    "\n",
    "            # print(\"blah\",dy.shape)\n",
    "            # if dy.shape[0] == self.inputs.shape[0]:\n",
    "            #     dy = dy.T\n",
    "            # print(\"blah\",dy.shape)\n",
    "            # dw = dy.dot(self.inputs)\n",
    "            # db = np.sum(dy, axis=1, keepdims=True)\n",
    "            # dx = np.dot(dy.T, self.weights.T)\n",
    "\n",
    "            self.weights -= learning_rate * dw.T\n",
    "            self.bias -= learning_rate * db\n",
    "\n",
    "            return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {0: [1, 1, 1, 0, 0, 0],\n",
    " 1: [0, 1, 1, 1, 0, 0],\n",
    " 2: [0, 0, 1, 1, 1, 0],\n",
    " 3: [0, 0, 0, 1, 1, 1],\n",
    " 4: [1, 0, 0, 0, 1, 1],\n",
    " 5: [1, 1, 0, 0, 0, 1],\n",
    " 6: [1, 1, 1, 1, 0, 0],\n",
    " 7: [0, 1, 1, 1, 1, 0],\n",
    " 8: [0, 0, 1, 1, 1, 1],\n",
    " 9: [1, 0, 0, 1, 1, 1],\n",
    " 10: [1, 1, 0, 0, 1, 1],\n",
    " 11: [1, 1, 1, 0, 0, 1],\n",
    " 12: [1, 1, 0, 1, 1, 0],\n",
    " 13: [0, 1, 1, 0, 1, 1],\n",
    " 14: [1, 0, 1, 1, 0, 1],\n",
    " 15: [1, 1, 1, 1, 1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  ' + str(test_X.shape))\n",
    "print('Y_test:  ' + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = Layers()\n",
    "C1 = layers.CONV(1,6,5)\n",
    "S2 = layers.POOL(2)\n",
    "C3 = layers.CONV(6,16,5)\n",
    "S4 = layers.POOL(2)\n",
    "C5 = layers.CONV(16,120,5)\n",
    "F6 = layers.DENSE(120,84,'tanh')\n",
    "F7 = layers.DENSE(84,10,'softmax')\n",
    "def forward_pass(im):\n",
    "  fmap1 = util.tanh(C1.forward(np.array([im]),2,1))\n",
    "  # print(\"C1 Done\", fmap1.shape)\n",
    "  fmap2 = S2.forward(fmap1,2)\n",
    "  # print(\"S2 Done\", fmap2.shape)\n",
    "  fmap3 = util.tanh(C3.forward(fmap2,0,1))\n",
    "  # print(\"C3 Done\", fmap3.shape)\n",
    "  fmap4 = S4.forward(fmap3,2)\n",
    "  # print(\"S4 Done\", fmap4.shape)\n",
    "  fmap5 = util.tanh(C5.forward(fmap4,0,1))\n",
    "  # print(\"C5 Done\", fmap5.shape)\n",
    "  fmap6 = F6.forward(fmap5[:,0])\n",
    "  # print(\"F6 Done\", fmap6.shape)\n",
    "  fmap7 = F7.forward(fmap6)\n",
    "  return [fmap1, fmap2, fmap3, fmap4, fmap5, fmap6, fmap7]\n",
    "\n",
    "\n",
    "all_layers = [C1, S2, C3, S4, C5, F6, F7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = forward_pass(train_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ind, to_print=True):\n",
    "    val = forward_pass(train_X[ind])\n",
    "    if to_print:\n",
    "        print(\"True Label:\", train_y[ind], \"Predicted:\", np.argmax(val[-1]))\n",
    "    return train_y[ind], np.argmax(val[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch:\",epoch)\n",
    "        for i, im in tqdm(enumerate(train_X[:10000])):\n",
    "            # if i%100==0:\n",
    "              # print(i, end=\" \")\n",
    "            label = util.one_hot(train_y[i])\n",
    "            fmaps = forward_pass(im)\n",
    "            t = F7.backward(fmaps[-1], learning_rate = 0.05)\n",
    "            t = F6.backward(t, learning_rate = 0.05)\n",
    "            t = C5.backward(t, stride = 1, learning_rate = 0.05)\n",
    "            t = S4.backward(t)\n",
    "            t = C3.backward(t, stride = 1, learning_rate = 0.05)\n",
    "            t = S2.backward(t)\n",
    "            t = C1.backward(t, stride = 1, learning_rate = 0.05)\n",
    "        acc = 0\n",
    "        for i in tqdm(range(10000,11000)):\n",
    "            x,y = test(i,to_print=False)\n",
    "            if x==y:\n",
    "                acc += 1\n",
    "        acc/=10\n",
    "        print(\"Acc:\",acc,\"percent\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "615it [01:32,  5.94it/s]"
     ]
    }
   ],
   "source": [
    "train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for i in tqdm(range(0,100)):\n",
    "  x,y = test(i,to_print=False)\n",
    "  if x==y:\n",
    "    acc += 1\n",
    "acc/=100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_pass(train_X[0])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
